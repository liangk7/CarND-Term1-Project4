{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import cv2\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Other\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Camera Calibration\n",
    "path_calImages = 'camera_cal'\n",
    "\n",
    "# Images\n",
    "path_imgIn = 'test_images/'\n",
    "path_imgOut = 'output_images/'\n",
    "\n",
    "# Videos\n",
    "path_vidIn = 'test_videos/'\n",
    "path_vidOut = 'output_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Source and destination points\n",
    "src = np.float32([[595, 450], # top left\n",
    "                  [689, 450], # top right\n",
    "                  [216, 719], # bottom left\n",
    "                  [1111, 719]]) # bottom right\n",
    "dst = np.float32([[380, 0], # top left\n",
    "                  [900, 0], # top right\n",
    "                  [380, 720], # bottom left\n",
    "                  [900, 720]]) # bottom right\n",
    "\n",
    "# Pixel distance (meters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Frame class stores image processing features\n",
    "class Frame():\n",
    "    def __init__(self):\n",
    "        # Image Depictions\n",
    "        self.orig = None # raw image\n",
    "        self.undst = None # camera calibrated original image\n",
    "        self.warp = None # aerial view of undistorted image\n",
    "        self.gray = None # grayscale of warped image\n",
    "        self.color_binary = None # binary grayscale using color space thresholds\n",
    "        self.sobel_binary = None # binary grayscale using sobel thresholds\n",
    "        self.combined_binary = None # binary combination of color and sobel binaries\n",
    "        self.detected_lanes = None # colormap of detected lanes\n",
    "        self.final = None # depiction of lane mask on undistorted image\n",
    "        self.collage = None # collage of all image steps\n",
    "        \n",
    "        # Image Properties\n",
    "        self.M = None\n",
    "        self.Minv = None\n",
    "        self.objpts = None\n",
    "        self.imgpts = None\n",
    "        \n",
    "        # Lane Lines\n",
    "        self.lineLeft = Line()\n",
    "        self.lineRight = Line()\n",
    "        \n",
    "        # Lane Properties\n",
    "        self.laneRad = None\n",
    "        self.lanePos = None\n",
    "        \n",
    "# Line class stores line calculation features\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        # Track if line characteristics were already found\n",
    "        self.found = False\n",
    "        \n",
    "        # Track line polynomials\n",
    "        self.polyNew = [] # new polynomial fit\n",
    "        self.polyOld = [] # existing polynomial fits\n",
    "        self.polyWorldNew = []\n",
    "        self.polyDiff = np.array([0, 0, 0], dtype='float')\n",
    "        \n",
    "        # Track line indeces\n",
    "        self.idx_X = None\n",
    "        self.idx_Y = None\n",
    "        \n",
    "        # Line curvature\n",
    "        self.curveRad = None\n",
    "        \n",
    "    def isFound(self):\n",
    "        return self.found\n",
    "    \n",
    "    def update(self, polyNew, polyTop, idx_X, idx_Y):\n",
    "        \n",
    "        if self.found:\n",
    "            self_polyDiff = self.polyNew[-1] - polyNew\n",
    "            \n",
    "        # Handler for new polynomial\n",
    "        if polyNew is not None:\n",
    "            self.found = True\n",
    "            self.idx_X = idx_X\n",
    "            self.idx_Y = idx_Y\n",
    "            \n",
    "            # Update polynomials\n",
    "            self.poly\n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(Frame):\n",
    "    '''\n",
    "    undistort image using camera calibration points\n",
    "    input: raw image, objpoints, imgpoints\n",
    "    output: undistorted image\n",
    "    '''\n",
    "    # Gather necessary Frame properties\n",
    "    img = Frame.orig\n",
    "    objpts = Frame.objpts\n",
    "    imgpts = Frame.imgpts\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    # Camera calibration\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpts, imgpts, img_size, None,None)\n",
    "    undst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    Frame.undst = undst\n",
    "    \n",
    "def unwarp(Frame, src, dst):\n",
    "    '''\n",
    "    unwarps image using source and destination points\n",
    "    input: undistorted image\n",
    "    output: unwarped image, Minv\n",
    "    '''\n",
    "    # Gather necessary Frame properties\n",
    "    undst = np.copy(Frame.undst)\n",
    "    img_size = (undst.shape[1], undst.shape[0])\n",
    "    # Store warp borders\n",
    "    srcBorder = np.array([[src[0][0],src[0][1]],[src[1][0],src[1][1]], [src[3][0],src[3][1]],[src[2][0],src[2][1]]], np.int32)\n",
    "    Frame.srcBorder = srcBorder\n",
    "    dstBorder = np.array([[dst[0][0],dst[0][1]],[dst[1][0],dst[1][1]], [dst[3][0],src[3][1]],[dst[2][0],dst[2][1]]], np.int32)\n",
    "    Frame.dstBorder = dstBorder\n",
    "    # Get and store transform parameters\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Frame.M = M\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    Frame.Min = Minv\n",
    "    # Do the warp\n",
    "    warp = cv2.warpPerspective(undst, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    Frame.warp = warp\n",
    "    \n",
    "def rectify(Frame):\n",
    "    '''\n",
    "    utilizes the pipeline outlined above: (HLS[2] & LAB[0]) | (Sobel_abs & Sobel_mag & Sobel_dir)\n",
    "    '''\n",
    "    # Gather necessary Frame properties\n",
    "    warp = cv2.cvtColor(Frame.warp, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(warp, cv2.COLOR_BGR2GRAY)\n",
    "    # Set color binary threshold parameters\n",
    "    colorThres_low = 150\n",
    "    colorThres_high = 255\n",
    "    # Set sobel binary threshold parameters\n",
    "    linKernel = 3\n",
    "    linThres_min = 15\n",
    "    linThres_max = 255\n",
    "    radKernel = 1\n",
    "    radThres_min = 0.01\n",
    "    radThres_max = 0.4\n",
    "    \n",
    "    # Color\n",
    "    s_channel = cv2.cvtColor(warp, cv2.COLOR_RGB2HLS)[:,:,2] # HLS, Schannel\n",
    "    l_channel = cv2.cvtColor(warp, cv2.COLOR_RGB2Lab)[:,:,0] # LAB, L channel\n",
    "\n",
    "    # Sobel\n",
    "    sobel_abs = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0)) # x direction\n",
    "    sobel_abs = np.uint8(255 * sobel_abs / np.max(sobel_abs)) # equalize to [0,255]\n",
    "    sobel_magx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=linKernel) # x direction\n",
    "    sobel_magy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=linKernel) # y direction\n",
    "    sobel_mag = np.sqrt(sobel_magx**2 + sobel_magy**2) # normalize across x and y\n",
    "    sobel_mag = np.uint8(255 * sobel_mag / np.max(sobel_mag)) # equalize to [0,255]\n",
    "    sobel_dirx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=radKernel)\n",
    "    sobel_diry = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=radKernel)\n",
    "    sobel_dir = np.arctan2(np.absolute(sobel_diry), np.absolute(sobel_dirx))\n",
    "\n",
    "    # Combined Binaries\n",
    "    color_binary = np.zeros_like(s_channel)\n",
    "    color_binary[(s_channel > colorThres_low) & (l_channel > colorThres_low)] = 1\n",
    "    Frame.color_binary = color_binary\n",
    "    sobel_binary = np.zeros_like(sobel_abs)\n",
    "    sobel_binary[((sobel_abs > linThres_min) & (sobel_abs <= linThres_max)) &\n",
    "                 ((sobel_mag > linThres_min) & (sobel_mag <= linThres_max)) &\n",
    "                 ((sobel_dir > radThres_min) & (sobel_dir <= radThres_max))] = 1\n",
    "    Frame.sobel_binary = sobel_binary\n",
    "    combined_binary = np.zeros_like(color_binary)\n",
    "    combined_binary[(color_binary == 1) | (sobel_binary == 1)] = 1\n",
    "    Frame.combined_binary = combined_binary\n",
    "    \n",
    "def lineFinder(Frame):\n",
    "    print('...')\n",
    "    \n",
    "def lineRefiner(Frame):\n",
    "    print('...')\n",
    "    \n",
    "def calcPos(Frame):\n",
    "    print('...')\n",
    "    \n",
    "    \n",
    "def drawLane(Frame):\n",
    "    print('...')\n",
    "    \n",
    "    \n",
    "def drawLine(img, poly, color):\n",
    "    print('...')\n",
    "    \n",
    "    \n",
    "def drawText(img, Frame):\n",
    "    print('...')\n",
    "    \n",
    "    \n",
    "def drawFinal(Frame):\n",
    "    print('...')\n",
    "    \n",
    "    \n",
    "def visualize(name, img):\n",
    "    cv2.namedWindow(name, cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow(name, img)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "def visualizeAll(Frame):\n",
    "    print('...')\n",
    "    \n",
    "    \n",
    "def processImage(img):\n",
    "    Frame.orig = img\n",
    "    undistort(Frame)\n",
    "    unwarp(Frame)\n",
    "    rectify(Frame)\n",
    "    '''if (Frame.leftLine.isFound() and Frame.rightLine.isFound()):\n",
    "        lineRefiner(Frame)\n",
    "    else:\n",
    "        lineFinder(Frame)\n",
    "    drawLane(Frame)\n",
    "    drawFinal(Frame)\n",
    "    collage(Frame)\n",
    "    visualize('collage', Frame.collage)'''\n",
    "    visualize('rectified', Frame.combined_binary)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameter\n",
    "if count == 0:\n",
    "    Frame = Frame()\n",
    "    count += 1\n",
    "\n",
    "# Generate object points\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "#Arrays to store object points and image points from all the images\n",
    "Frame.objpoints = [] #3d points in real world space\n",
    "Frame.imgpoints = [] # 2d points in image plane\n",
    "\n",
    "#Make a list of calibration images\n",
    "images = glob.glob(path_calImages + '*.jpg')\n",
    "\n",
    "#Step through the lsit and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #find corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    #If found, add object points, image points\n",
    "    if ret == True:\n",
    "        Frame.objpoints.append(objp)\n",
    "        Frame.imgpoints.append(corners)\n",
    "\n",
    "        #Draw and display the corners\n",
    "\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "/Users/jenkins/miniconda/1/x64/conda-bld/conda_1486587097465/work/opencv-3.1.0/modules/calib3d/src/calibration.cpp:3314: error: (-215) nimages > 0 in function calibrateCamera\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f4203657b38c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprocessed_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-4b50385cbb5d>\u001b[0m in \u001b[0;36mprocessImage\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocessImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mundistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0munwarp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mrectify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4b50385cbb5d>\u001b[0m in \u001b[0;36mundistort\u001b[0;34m(Frame)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Camera calibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mundst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundistort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mundst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /Users/jenkins/miniconda/1/x64/conda-bld/conda_1486587097465/work/opencv-3.1.0/modules/calib3d/src/calibration.cpp:3314: error: (-215) nimages > 0 in function calibrateCamera\n"
     ]
    }
   ],
   "source": [
    "test_images = glob.glob(path_imgIn + '*.jpg')\n",
    "n_test_images = int(len(test_images))\n",
    "\n",
    "test_image = cv2.imread(test_images[np.random.randint(n_test_images)])\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "processed_image = processImage(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
